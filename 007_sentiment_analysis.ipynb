{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "007_sentiment_analysis",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andrybrew/pythondataanalytics/blob/master/007_sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Y64-VX3WSZ8",
        "colab_type": "text"
      },
      "source": [
        "# Sentiment Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQui_5U19fug",
        "colab_type": "text"
      },
      "source": [
        "Sentiment analysis (also known as opinion mining or emotion AI) refers to the use of natural language processing, text analysis, computational linguistics, and biometrics to systematically identify, extract, quantify, and study affective states and subjective information.\n",
        "\n",
        "To collect twitter data in python, we can use Tweepy. Tweepy is the most popular Python Package for accessing the Twitter API, You can read the full documentation [HERE](https://tweepy.readthedocs.io/en/latest/). In this practice, we will practice to get tweet data using a specific keyword and do some sentiment analysis from the tweet collected. \n",
        "\n",
        "*In this practice we will use a prebuild sentiment analysis model, namely NLTK Vader sentiment. Unfortunately, this model only supports English.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oT77BLYo45C",
        "colab_type": "text"
      },
      "source": [
        "## Collecting Twitter Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qK9C5mLS-uSJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install Library\n",
        "!pip install tweepy\n",
        "!pip install vaderSentiment"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c96ziFJK-to7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Library\n",
        "import tweepy\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAdK1U5ytfyo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fill the API Key\n",
        "\n",
        "# consumer_key = 'Masukkan Consumer Key'\n",
        "# consumer_secret = 'Masukkan Consumer Secret Key'\n",
        "# access_token = 'Masukkan Access token'\n",
        "# access_token_secret = 'Masukkan Access Token Secret'\n",
        "\n",
        "consumer_key = '8c6g53lSeupE2anReETTs2vys'\n",
        "consumer_secret = 'OltZDimReEajo9AEBAsAPqf78yyNzfrmH85aJzUzpqjAsH4Nxf'\n",
        "access_token = '201094280-dsxUFTbrXldpm8YjkziHqkmFqCkF9aRH4lLvq1oE'\n",
        "access_token_secret = 'VBpKAHnNCQjGjRpCLsrHROHufWX8tEbP3EAYblbYKNv5c'\n",
        "\n",
        "# Auth. \n",
        "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "api = tweepy.API(auth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2d4CRt7uw4wG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Finding tweets by Keyword\n",
        "tweets = api.search('startup', count=1000, lang='en')\n",
        "tweets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFEH8_gKy0Fa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print the collected tweet\n",
        "data = pd.DataFrame(data=[tweet.text for tweet in tweets], columns=['Tweets'])\n",
        "display(data.head(10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epo1db2ho1eJ",
        "colab_type": "text"
      },
      "source": [
        "## Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWdJc9fJy42Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import library for Text Analytics\n",
        "import nltk\n",
        "nltk.download('vader_lexicon')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CtyY93_zv1z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Sentiment Analysis\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "listy = [] \n",
        "for index, row in data.iterrows():\n",
        "  ss = sid.polarity_scores(row[\"Tweets\"])\n",
        "  listy.append(ss)\n",
        "  \n",
        "se = pd.Series(listy)\n",
        "data['polarity'] = se.values\n",
        "display(data.head(10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrT_ZUHtP1EI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pie Chart Visualization\n",
        "labels = ['negative', 'neutral', 'positive']\n",
        "sizes  = [ss['neg'], ss['neu'], ss['pos']]\n",
        "plt.pie(sizes, labels=labels, autopct='%1.1f%%')\n",
        "plt.axis('equal') \n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}